{
  "name": "Local-Ai-Code",
  "displayName": "Local AI",
  "publisher": "EZOpenSource",
  "version": "0.0.9 ",
  "description": "A fully local AI coding assistant for Visual Studio Code with project-wide context and guarded command/file execution.",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://example.com/ai-code.git"
  },
  "bugs": {
    "url": "https://example.com/ai-code/issues"
  },
  "engines": {
    "vscode": "^1.85.0"
  },
  "categories": [
    "Other"
  ],
  "keywords": [
    "ai",
    "assistant",
    "code",
    "local"
  ],
  "activationEvents": [
  ],
  "main": "./dist/extension.js",
  "scripts": {
    "compile": "tsc -p .",
    "watch": "tsc -w -p .",
    "lint": "echo 'No linters configured'",
    "test": "npm run compile && node --test --experimental-test-module-mocks dist/test"
  },
  "contributes": {
    "commands": [
      {
        "command": "ai-code.askAssistant",
        "title": "Local Ai Coder: Ask",
        "category": "Local Ai Coder"
      },
      {
        "command": "ai-code.resetConversation",
        "title": "Local Ai Coder: Reset Conversation",
        "category": "Local Ai Coder"
      },
      {
        "command": "ai-code.showLastPlan",
        "title": "Local Ai Coder: Show Last Plan",
        "category": "Local Ai Coder"
      },
      {
        "command": "ai-code.openSettings",
        "title": "Local Ai Coder: Open Settings",
        "category": "Local Ai Coder"
      },
      {
        "command": "ai-code.addOllamaModel",
        "title": "Local Ai Coder: Add Ollama Model",
        "category": "Local Ai Coder"
      },
      {
        "command": "ai-code.removeModel",
        "title": "Local Ai Coder: Remove Model",
        "category": "Local Ai Coder"
      },
      {
        "command": "ai-code.downloadModel",
        "title": "Local Ai Coder: Download Model",
        "category": "Local Ai Coder"
      },
      {
        "command": "ai-code.resetSettings",
        "title": "Local Ai Coder: Reset Settings",
        "category": "Local Ai Coder"
      },
      {
        "command": "ai-code.runDebugPrompt",
        "title": "Local Ai Coder: Run Debug Prompt",
        "category": "Local Ai Coder"
      }
    ],
    "configuration": {
      "type": "object",
      "title": "Local Ai Coder",
      "properties": {
        "ai-code.modelId": {
          "type": "string",
          "default": "ollama:qwen2.5-coder:7b",
          "description": "Primary Ollama model identifier (use the form ollama:model). Defaults to `ollama:qwen2.5-coder:7b` for a strong 7B planner that fits in 16 GB of RAM."
        },
        "ai-code.collaboratorModelId": {
          "type": "string",
          "default": "ollama:deepseek-coder:6.7b",
          "description": "Secondary Ollama model identifier for the reviewer that refines the primary plan. Defaults to `ollama:deepseek-coder:6.7b`. Clear the value to reuse the planning model."
        },
        "ai-code.coderModelId": {
          "type": "string",
          "default": "",
          "description": "Optional Ollama model identifier dedicated to the coding stage. Leave blank to reuse the reviewer model."
        },
        "ai-code.verifierModelId": {
          "type": "string",
          "default": "ollama:phi3:mini",
          "description": "Dedicated Ollama model identifier for verifying that responses are valid JSON. Defaults to `ollama:phi3:mini`. Clear the value to reuse the collaborator model."
        },
        "ai-code.promptBuilders.planner": {
          "type": "string",
          "default": "",
          "description": "Prompt builder identifier for the planning role. Leave blank to use the default comprehensive prompt."
        },
        "ai-code.promptBuilders.contextScout": {
          "type": "string",
          "default": "",
          "description": "Prompt builder identifier for the context scout role. Leave blank to match the planner prompt builder."
        },
        "ai-code.promptBuilders.reviewer": {
          "type": "string",
          "default": "",
          "description": "Prompt builder identifier for the reviewer role. Leave blank to match the planner prompt builder."
        },
        "ai-code.promptBuilders.coder": {
          "type": "string",
          "default": "",
          "description": "Prompt builder identifier for the coding role. Leave blank to inherit from the reviewer prompt builder."
        },
        "ai-code.promptBuilders.qa": {
          "type": "string",
          "default": "",
          "description": "Prompt builder identifier for the QA role. Leave blank to match the reviewer prompt builder."
        },
        "ai-code.promptBuilders.safety": {
          "type": "string",
          "default": "",
          "description": "Prompt builder identifier for the safety role. Leave blank to match the QA prompt builder."
        },
        "ai-code.promptBuilders.verifier": {
          "type": "string",
          "default": "",
          "description": "Prompt builder identifier for the verification role. Leave blank to match the safety prompt builder."
        },
        "ai-code.collaboration.showLiveStream": {
          "type": "boolean",
          "default": false,
          "description": "Stream planner and reviewer updates live while they collaborate on a plan."
        },
        "ai-code.maxNewTokens": {
          "type": "number",
          "default": 16384,
          "minimum": 32,
          "maximum": 16384,
          "description": "Maximum number of tokens the assistant will generate per response."
        },
        "ai-code.temperature": {
          "type": "number",
          "default": 0.2,
          "minimum": 0,
          "maximum": 2,
          "description": "Sampling temperature to control response creativity."
        },
        "ai-code.temperature.contextScout": {
          "type": "number",
          "default": 0.2,
          "minimum": 0,
          "maximum": 2,
          "description": "Override sampling temperature for the context scout role."
        },
        "ai-code.temperature.planner": {
          "type": "number",
          "default": 0.2,
          "minimum": 0,
          "maximum": 2,
          "description": "Override sampling temperature for the planner role."
        },
        "ai-code.temperature.reviewer": {
          "type": "number",
          "default": 0.2,
          "minimum": 0,
          "maximum": 2,
          "description": "Override sampling temperature for the reviewer role."
        },
        "ai-code.temperature.qa": {
          "type": "number",
          "default": 0.2,
          "minimum": 0,
          "maximum": 2,
          "description": "Override sampling temperature for the QA role."
        },
        "ai-code.temperature.safety": {
          "type": "number",
          "default": 0.2,
          "minimum": 0,
          "maximum": 2,
          "description": "Override sampling temperature for the safety auditor role."
        },
        "ai-code.temperature.verifier": {
          "type": "number",
          "default": 0,
          "minimum": 0,
          "maximum": 2,
          "description": "Override sampling temperature for the verifier role."
        },
        "ai-code.context.maxFiles": {
          "type": "number",
          "default": 40,
          "minimum": 1,
          "maximum": 200,
          "description": "Maximum number of project files to stream into the assistant's context."
        },
        "ai-code.context.maxFileSize": {
          "type": "number",
          "default": 200,
          "minimum": 1,
          "description": "Maximum size (in kilobytes) for any individual file included in the context.",
          "markdownDescription": "Interpreted as kilobytes. For example, enter `200` for a 200 KB limit. Existing byte-based values are converted automatically."
        },
        "ai-code.context.maxTotalSize": {
          "type": "number",
          "default": 1500,
          "minimum": 20,
          "description": "Maximum total size (in kilobytes) of all files combined in the context window.",
          "markdownDescription": "Interpreted as kilobytes. For example, enter `1500` for a 1.5 MB combined limit. Existing byte-based values are converted automatically."
        },
        "ai-code.allowCommandExecution": {
          "type": "boolean",
          "default": true,
          "description": "Allow the assistant to suggest shell/Powershell commands that require user approval before execution."
        },
        "ai-code.shell": {
          "type": "string",
          "default": "default",
          "description": "Shell executable to use for approved commands. Use 'powershell' on Windows to force PowerShell usage."
        },
        "ai-code.context.includeBinary": {
          "type": "boolean",
          "default": false,
          "description": "Allow binary files to be included in the context (not recommended)."
        },
        "ai-code.context.excludeGlobs": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "default": [],
          "description": "Additional glob patterns to exclude when collecting context."
        },
        "ai-code.context.overrideDefaultExcludes": {
          "type": "boolean",
          "default": false,
          "description": "If true, ignore the built-in exclude list and rely solely on context.excludeGlobs."
        },
        "ai-code.context.prioritizeChangedFiles": {
          "type": "boolean",
          "default": true,
          "description": "Gather Git changed and staged files before scanning the rest of the workspace."
        },
        "ai-code.ollama.requestTimeoutMs": {
          "type": "number",
          "default": 30,
          "minimum": 0,
          "description": "Timeout in seconds for Ollama REST requests such as /api/pull and /api/show.",
          "markdownDescription": "Interpreted as seconds. Enter `30` for a 30 second timeout. Existing millisecond-based values are converted automatically."
        },
        "ai-code.ollama.generationTimeoutMs": {
          "type": "number",
          "default": 120,
          "minimum": 0,
          "description": "Timeout in seconds for Ollama generation streaming requests.",
          "markdownDescription": "Interpreted as seconds. Enter `120` for a two-minute timeout. Set to `0` or a negative number to disable the timeout. Existing millisecond-based values are converted automatically."
        },
        "ai-code.sampling.topP": {
          "type": "number",
          "default": 0.95,
          "minimum": 0,
          "maximum": 1,
          "description": "Top-p nucleus sampling value forwarded to Ollama generations."
        },
        "ai-code.sampling.topP.contextScout": {
          "type": "number",
          "default": 0.95,
          "minimum": 0,
          "maximum": 1,
          "description": "Override top-p sampling weight for the context scout role."
        },
        "ai-code.sampling.topP.planner": {
          "type": "number",
          "default": 0.95,
          "minimum": 0,
          "maximum": 1,
          "description": "Override top-p sampling weight for the planner role."
        },
        "ai-code.sampling.topP.reviewer": {
          "type": "number",
          "default": 0.95,
          "minimum": 0,
          "maximum": 1,
          "description": "Override top-p sampling weight for the reviewer role."
        },
        "ai-code.sampling.topP.qa": {
          "type": "number",
          "default": 0.95,
          "minimum": 0,
          "maximum": 1,
          "description": "Override top-p sampling weight for the QA role."
        },
        "ai-code.sampling.topP.safety": {
          "type": "number",
          "default": 0.95,
          "minimum": 0,
          "maximum": 1,
          "description": "Override top-p sampling weight for the safety auditor role."
        },
        "ai-code.sampling.topP.verifier": {
          "type": "number",
          "default": 0.95,
          "minimum": 0,
          "maximum": 1,
          "description": "Override top-p sampling weight for the verifier role."
        },
        "ai-code.sampling.repetitionPenalty": {
          "type": "number",
          "default": 1.05,
          "minimum": 0,
          "maximum": 2,
          "description": "Repetition penalty applied during generation."
        },
        "ai-code.sampling.repetitionPenalty.contextScout": {
          "type": "number",
          "default": 1.05,
          "minimum": 0,
          "maximum": 2,
          "description": "Override repetition penalty for the context scout role."
        },
        "ai-code.sampling.repetitionPenalty.planner": {
          "type": "number",
          "default": 1.05,
          "minimum": 0,
          "maximum": 2,
          "description": "Override repetition penalty for the planner role."
        },
        "ai-code.sampling.repetitionPenalty.reviewer": {
          "type": "number",
          "default": 1.05,
          "minimum": 0,
          "maximum": 2,
          "description": "Override repetition penalty for the reviewer role."
        },
        "ai-code.sampling.repetitionPenalty.qa": {
          "type": "number",
          "default": 1.05,
          "minimum": 0,
          "maximum": 2,
          "description": "Override repetition penalty for the QA role."
        },
        "ai-code.sampling.repetitionPenalty.safety": {
          "type": "number",
          "default": 1.05,
          "minimum": 0,
          "maximum": 2,
          "description": "Override repetition penalty for the safety auditor role."
        },
        "ai-code.sampling.repetitionPenalty.verifier": {
          "type": "number",
          "default": 1.05,
          "minimum": 0,
          "maximum": 2,
          "description": "Override repetition penalty for the verifier role."
        }
      }
    },
    "viewsContainers": {
      "activitybar": [
        {
          "id": "ai-code",
          "title": "Local Ai Coder",
          "icon": "media/local-ai-coder-icon.svg"
        }
      ]
    },
    "views": {
      "ai-code": [
        {
          "type": "webview",
          "id": "ai-code.chatView",
          "name": "Local Ai Coder",
          "contextualTitle": "Local Ai Coder"
        },
        {
          "id": "ai-code.quickActions",
          "name": "Quick Actions"
        }
      ]
    },
    "menus": {
      "view/title": [
        {
          "command": "ai-code.openSettings",
          "when": "view == ai-code.chatView",
          "group": "navigation@99",
          "icon": "$(gear)"
        }
      ]
    }
  },
  "devDependencies": {
    "@types/node": "^24.5.1",
    "@types/vscode": "^1.85.0",
    "typescript": "^5.9.2"
  },
  "dependencies": {
    "jsonc-parser": "^3.3.1"
  }
}
